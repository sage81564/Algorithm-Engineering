{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See Chapter 2, Deep Learning with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple machine learning model to show the big picture and then learn the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the shape of train_images and test_imiages?\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# what is the length of the train labels and test labels?\n",
    "print(len(train_labels))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of training examples = 60000\n",
      "the number of classes = 10\n",
      "Dimention of images = 60000 x 28  \n",
      "The number of occurances of each class in the dataset = {0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}  \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the images\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"the number of training examples = %i\" % train_images.shape[0])\n",
    "print(\"the number of classes = %i\" % len(np.unique(train_labels)))\n",
    "print(\"Dimention of images = {:d} x {:d}  \".format(train_images.shape[0],train_images.shape[1])  )\n",
    "\n",
    "#This line will allow us to know the number of occurrences of each specific class in the data\n",
    "unique, count= np.unique(train_labels, return_counts=True)\n",
    "print(\"The number of occurances of each class in the dataset = %s \" % dict (zip(unique, count) ), \"\\n\" )\n",
    "\n",
    "# how many images to display (rows*columns)\n",
    "rows = 2\n",
    "columns = 3\n",
    "for index in range(rows*columns):\n",
    "    plt.subplot(rows, columns, index + 1)\n",
    "    plt.imshow(train_images[index], cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "    plt.title('label: ' + str(train_labels[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "1. Feed the neural network the training data (train_imges, train_labels)\n",
    "2. The network will learn to associate images and labels\n",
    "3. Use the test_images to verify if th epredictions match teh labels from test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512,activation='relu',input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three important concepts\n",
    "* Loss function- How the network will measure its performance on the training data\n",
    "* Optimizer- The mechanism through with cht e ntwork will update itself based on the data its been presented and its loss function\n",
    "* Metrics to monitor during training and testing- in this case we will use accuarcy (the fraction of the images that were correctly classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape the data into a form the network accepts\n",
    "# transorm the data from an array shape (6000, 28, 28) of type uint8 with values [0,255] to\n",
    "# a float32 array with shape (6000, 28*28) with values between and 1\n",
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorial encode the lables (explained in detail later)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 1.4781 - accuracy: 0.6667\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.5876 - accuracy: 0.8533\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.4114 - accuracy: 0.8887\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.3532 - accuracy: 0.9006\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.3239 - accuracy: 0.9075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cfa66b3348>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "network.fit(train_images,train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 48.5575 - accuracy: 0.8354\n",
      "test accuracy: 0.8353999853134155\n"
     ]
    }
   ],
   "source": [
    "# Run the model on the test data\n",
    "test_loss,test_acc = network.evaluate(test_images,test_labels)\n",
    "print('test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "1. Why is the accuracy lower on the test data than the training data?\n",
    "2. Create your own test image of a 4 and an 8 using Microsoft Paint (28,28) pixels and test the images using the model\n",
    "3. Describe your findings and why the model is accurate or not accurate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
